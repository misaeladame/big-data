{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Web scraping Blogs, foros, sitios oficiales de datos, etc. Función de recopilar esa información: comparación de precios, análisis de opinión sobre productos/servicios, chatbots, etc. No hay tenemos límite en cuanto creatividad de trabajar con la información. Existen sitios donde tienen derechos de autor, habrá que tener cuidado. Hay más sitios que tienen un concepto datos libres: cada vez más organizaciones tienen secciones de datos (csv, bd, xslx, json)\n",
    "\n",
    "Hay 3 formatos: Fuentes de información:\n",
    "\n",
    "* Paginas web pueden incluir: csv, json, xml, etc.\n",
    "* API-REST json, xml\n",
    "* Páginas que contienen la información en formato \"humano\": python tiene varias librerias:\n",
    "    1. Acceder por medio de una URL, descarga inforamción y luego podemos utlizar desde python un paquete: **BeautifulSoup**\n",
    "    2. Si requiere realizar un proceso en la información (extra) entonces se utiliza un paquete: **Selenium** (permite desde python hacer todo como si estuvieramos en el navegador)\n",
    "    3. Python: **requests**\n",
    "    \n",
    "Resumiendo: \n",
    "\n",
    "* Archivos incluidos en la página web : requests, csv, json, etc. \n",
    "* API-REST : Requests \n",
    "* Datos incrustados en la página web (incluidos): BeautifilSoup \n",
    "* Datos que requieren de proceso/interacción: Selenium.\n",
    "\n",
    "Archivos incluidos en la página web: URI, IRL, URN\n",
    "\n",
    "**URI (Uniform Resource Identifier):** cadena de caracteres que identifica un recurso. \n",
    "\n",
    "Sintaxis general: schema:[//[user[:passwd]@host[:port]][/path][?query][#tag]]\n",
    "\n",
    "* https://es.wikipedia.org/wiki/Pandemia_de_COVID-19\n",
    "* https://es.wikipedia.org/wiki/Pandemia_de_COVID-19#Am%C3%A9rica\n",
    "* https://www.youtube.com/watch?V=183IwSzCgV4\n",
    "\n",
    "URI se divide en dos partes: URL y URN\n",
    "\n",
    "* URL (uniform resource lcoator) direcciones en la www\n",
    "    * ftp://teclaguna.edu.mx\n",
    "* URN (Uniform Resource Name)\n",
    "    * urn:isbn:0451450523\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#Archivos incluidos en la página web\n",
    "import requests\n",
    "url = \"http://www.gutenberg.org/ebooks/1112.txt.utf-8\"\n",
    "resp = requests.get(url)\n",
    "print(resp) #https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\jmas_\\\\Jupyter\\\\Datasets\\\\\"\n",
    "with open(path + \"ryj.text\", \"wb\") as arch:\n",
    "    arch.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29174\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "signos = \",*./#[] \"\n",
    "cuenta = 0\n",
    "pal = [] #Lista\n",
    "with urllib.request.urlopen(\"http://www.gutenberg.org/ebooks/1112.txt.utf-8\") as info:\n",
    "    for linea in info.readlines():\n",
    "        limpia = linea.decode(\"utf-8\").lower()\n",
    "        for s in signos:\n",
    "            limpia = limpia.replace(s, \" \") #Gracias Octavio!!!\n",
    "            #cuenta = cuenta + 1\n",
    "        #extend append en la lista\n",
    "        pal.extend(limpia.split())\n",
    "#print(cuenta)\n",
    "print(len(pal))\n",
    "#print(pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheProjectGutenbergEBookofRomeoandJulietbyWilliamShakespeare'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla = str.maketrans({letra: None for letra in \",*./#[] \"})\n",
    "\"The Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare\".translate(tabla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otra manera: expresiones regulares\n",
    "apellido = (\"capulet\", \"montague\")\n",
    "nombres = (\"romeo\", \"juliet\", \"tybalt\", \"mercutio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = {a: pal.count(a) for a in apellido}\n",
    "no = {n: pal.count(n) for n in nombres}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capulet': 29, 'montague': 26}\n",
      "{'romeo': 111, 'juliet': 56, 'tybalt': 47, 'mercutio': 19}\n"
     ]
    }
   ],
   "source": [
    "print(ap)\n",
    "print(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([29, 26])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora a graficar :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
